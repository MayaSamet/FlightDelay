{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "    \n",
    "- Using OneHotEncoder Columns with regresison\n",
    "- Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file as dataframe \n",
    "# import pyspark modules\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, Bucketizer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "import functools \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"app\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .config('spark.cores.max', '2') \\\n",
    "    .config(\"spark.driver.memory\",'4g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(\"/home/jovyan/FlightDelay/clean_data_no_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").option(\"inferschema\",\"true\").load(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>B_SCHEDULED_ARRIVAL</th>\n",
       "      <th>B_ARRIVAL_TIME</th>\n",
       "      <th>B_SCHEDULED_DEPARTURE</th>\n",
       "      <th>B_DEPARTURE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2459</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>500</td>\n",
       "      <td>1476</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>699</td>\n",
       "      <td>PHX</td>\n",
       "      <td>CLT</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>1773</td>\n",
       "      <td>804</td>\n",
       "      <td>728</td>\n",
       "      <td>-36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1890</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>545</td>\n",
       "      <td>...</td>\n",
       "      <td>731</td>\n",
       "      <td>849</td>\n",
       "      <td>847</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>6457</td>\n",
       "      <td>SMX</td>\n",
       "      <td>LAX</td>\n",
       "      <td>545</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>651</td>\n",
       "      <td>1476</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5160</td>\n",
       "      <td>OMA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>550</td>\n",
       "      <td>...</td>\n",
       "      <td>781</td>\n",
       "      <td>810</td>\n",
       "      <td>831</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER ORIGIN_AIRPORT  \\\n",
       "0    0  2015      1    1            4      AA           2459            PHX   \n",
       "1    1  2015      1    1            4      US            699            PHX   \n",
       "2    2  2015      1    1            4      DL           1890            DFW   \n",
       "3    3  2015      1    1            4      OO           6457            SMX   \n",
       "4    4  2015      1    1            4      OO           5160            OMA   \n",
       "\n",
       "  DESTINATION_AIRPORT  SCHEDULED_DEPARTURE        ...         DISTANCE  \\\n",
       "0                 DFW                  200        ...              868   \n",
       "1                 CLT                  220        ...             1773   \n",
       "2                 ATL                  545        ...              731   \n",
       "3                 LAX                  545        ...              134   \n",
       "4                 IAH                  550        ...              781   \n",
       "\n",
       "   SCHEDULED_ARRIVAL  ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  \\\n",
       "0                500          1476              4         0          1   \n",
       "1                804           728            -36         0          0   \n",
       "2                849           847             -2         0          0   \n",
       "3                651          1476              4         0          1   \n",
       "4                810           831             21         0          0   \n",
       "\n",
       "   B_SCHEDULED_ARRIVAL  B_ARRIVAL_TIME  B_SCHEDULED_DEPARTURE  \\\n",
       "0                  1.0             4.0                    0.0   \n",
       "1                  2.0             2.0                    0.0   \n",
       "2                  2.0             2.0                    1.0   \n",
       "3                  2.0             4.0                    1.0   \n",
       "4                  2.0             2.0                    1.0   \n",
       "\n",
       "   B_DEPARTURE_TIME  \n",
       "0               4.0  \n",
       "1               0.0  \n",
       "2               2.0  \n",
       "3               4.0  \n",
       "4               2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder \n",
    "\n",
    "since vector type didn't transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"AIRLINE\", outputCol=\"AIRLINE_Index\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"AIRLINE_Index\", outputCol=\"AIRLINE_Vec\")\n",
    "encoded = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer2 = StringIndexer(inputCol=\"ORIGIN_AIRPORT\", outputCol=\"ORIGIN_AIRPORT_Index\")\n",
    "model2 = stringIndexer2.fit(encoded)\n",
    "indexed2 = model2.transform(encoded)\n",
    "\n",
    "encoder2 = OneHotEncoder(inputCol=\"ORIGIN_AIRPORT_Index\", outputCol=\"ORIGIN_AIRPORT_Vec\")\n",
    "encoded2 = encoder2.transform(indexed2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+-----------------------+\n",
      "|DESTINATION_AIRPORT|DESTINATION_AIRPORT_Index|DESTINATION_AIRPORT_Vec|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                CLT|                     14.0|       (585,[14],[1.0])|\n",
      "|                ATL|                      0.0|        (585,[0],[1.0])|\n",
      "|                LAX|                      3.0|        (585,[3],[1.0])|\n",
      "|                IAH|                      5.0|        (585,[5],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                FLL|                     22.0|       (585,[22],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                MCO|                     10.0|       (585,[10],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                PHL|                     24.0|       (585,[24],[1.0])|\n",
      "|                ATL|                      0.0|        (585,[0],[1.0])|\n",
      "|                LAS|                      7.0|        (585,[7],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (585,[2],[1.0])|\n",
      "|                SEA|                     11.0|       (585,[11],[1.0])|\n",
      "|                ORD|                      1.0|        (585,[1],[1.0])|\n",
      "|                DEN|                      4.0|        (585,[4],[1.0])|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer3 = StringIndexer(inputCol=\"DESTINATION_AIRPORT\", outputCol=\"DESTINATION_AIRPORT_Index\")\n",
    "model3 = stringIndexer3.fit(encoded2)\n",
    "indexed3 = model3.transform(encoded2)\n",
    "\n",
    "encoder3 = OneHotEncoder(inputCol=\"DESTINATION_AIRPORT_Index\", outputCol=\"DESTINATION_AIRPORT_Vec\")\n",
    "encoded3 = encoder3.transform(indexed3)\n",
    "encoded3.select('DESTINATION_AIRPORT','DESTINATION_AIRPORT_Index', \"DESTINATION_AIRPORT_Vec\").show()\n",
    "#encoded3.cache()b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_to_drop = ['AIRLINE_Index', 'AIRLINE', 'ORIGIN_AIRPORT_Index', \n",
    "                    'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT_Index',\n",
    "                    'DESTINATION_AIRPORT', 'FLIGHT_NUMBER']\n",
    "\n",
    "final_encoded = encoded3.drop(*new_cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'DEPARTURE_TIME',\n",
       " 'DEPARTURE_DELAY',\n",
       " 'SCHEDULED_TIME',\n",
       " 'ELAPSED_TIME',\n",
       " 'DISTANCE',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'ARRIVAL_TIME',\n",
       " 'ARRIVAL_DELAY',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_ARRIVAL_TIME',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'B_DEPARTURE_TIME',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = final_encoded.withColumn('CANCELLED2', final_encoded.CANCELLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_encoded.drop('_c0', 'YEAR', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'ARRIVAL_TIME', \n",
    "                              'B_ARRIVAL_TIME', 'ELASPED TIME', 'B_ARRIVAL_TIME', \n",
    "                              'B_DEPARTURE_TIME', 'DEPARTURE_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- B_SCHEDULED_ARRIVAL: double (nullable = true)\n",
      " |-- B_SCHEDULED_DEPARTURE: double (nullable = true)\n",
      " |-- AIRLINE_Vec: vector (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_Vec: vector (nullable = true)\n",
      " |-- DESTINATION_AIRPORT_Vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convery final_encoded to rdd \n",
    "# we cannpot scale bucketized or vec columns, so we omit those form the scaling process\n",
    "input_data = final_df.rdd.map(lambda x: (x[9], DenseVector(x[1:9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, DenseVector([1.0, 4.0, 200.0, 120.0, 137.0, 868.0, 500.0, 0.0])),\n",
       " (0, DenseVector([1.0, 4.0, 220.0, 224.0, 199.0, 1773.0, 804.0, 0.0])),\n",
       " (0, DenseVector([1.0, 4.0, 545.0, 124.0, 104.0, 731.0, 849.0, 0.0]))]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = sqlCtx.createDataFrame(input_data, [\"label\",\"features2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StandardScaler(inputCol = \"features2\", outputCol = \"features_scaled\")\n",
    "\n",
    "scaler = SS.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data in df2 with our scaler \n",
    "scaled_df = scaler.transform(df2)\n",
    "#join scalable feature with columns  'AIRLINE_Vec', 'ORIGIN_AIRPORT_Vec', \n",
    "#'DESTINATION_AIRPORT_Vec', 'B_SCHEDULED_ARRIVAL', 'B_ARRIVAL_TIME', \n",
    "#'B_SCHEDULED_DEPARTURE','B_DEPARTURE_TIME'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|           features2|     features_scaled|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[1.0,4.0,200.0,12...|[0.11458541287952...|\n",
      "|    0|[1.0,4.0,220.0,22...|[0.11458541287952...|\n",
      "|    0|[1.0,4.0,545.0,12...|[0.11458541287952...|\n",
      "|    1|[1.0,4.0,545.0,66...|[0.11458541287952...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no common column between these two dataframes add row_index so that it can be joined\n",
    "scaled_df = scaled_df.withColumn('row_index', F.monotonically_increasing_id())\n",
    "final_df = final_df.withColumn('row_index', F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scaled df and final_df\n",
    "total_df = scaled_df.join(final_df, scaled_df.row_index == final_df.row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100986"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'row_index',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'SCHEDULED_TIME',\n",
       " 'ELAPSED_TIME',\n",
       " 'DISTANCE',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec',\n",
       " 'row_index']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns of already scaled predictors \n",
    "total_df = total_df.drop(*['MONTH', 'DAY', 'DAY_OF_WEEK', 'SCHEDULED_DEPARTURE', 'SCHEDULED_TIME', 'DISTANCE',\n",
    "                           'SCHEDULED_ARRIVAL', 'DIVERTED', \n",
    "                           'CANCELLED2', 'row_index']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100986"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'ELAPSED_TIME',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final scaled dataframe for predicting Cancelled flights \n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled: split data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaled train/test with one-hot-encoded columns\n",
    "train_data_scaled, test_data_scaled = total_df.randomSplit(seed= 314, weights= [.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaled train/test without one-hot-encoded columns \n",
    "train_data_scaled_no_hot, test_data_scaled_no_hot = scaled_df.randomSplit(seed = 314, weights = [0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even out scaled dataframe with no one hot encoded\n",
    "c_no_hot = train_data_scaled_no_hot.where(scaled_df.label ==1)\n",
    "not_c_no_hot = train_data_scaled_no_hot.where(scaled_df.label ==0).sample(False, 0.025, 454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_no_hot.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_c_no_hot.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+\n",
      "|label|           features2|     features_scaled|row_index|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "|    1|[1.0,1.0,805.0,20...|[0.11458541287952...|    45566|\n",
      "|    1|[1.0,1.0,1200.0,7...|[0.11458541287952...|    45639|\n",
      "|    1|[1.0,1.0,1552.0,9...|[0.11458541287952...|    45700|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union scaled training data no hot \n",
    "training_data_scaled_no_hot = unionAll([c_no_hot, not_c_no_hot])\n",
    "training_data_scaled_no_hot.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_data_scaled.where(total_df.label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to filter out large portion of non-canclelled flights in training data to make data more even \n",
    "not_c = train_data_scaled.where(total_df.label == 0).sample(False, .025, 454) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1295"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+\n",
      "|label|           features2|     features_scaled|CANCELLED|B_SCHEDULED_ARRIVAL|B_ARRIVAL_TIME|B_SCHEDULED_DEPARTURE|B_DEPARTURE_TIME|   AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|\n",
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+\n",
      "|    1|[1.0,1.0,805.0,13...|[0.11458541287952...|        1|                4.0|           4.0|                  2.0|             4.0|(13,[5],[1.0])|   (593,[4],[1.0])|       (585,[41],[1.0])|\n",
      "|    1|[1.0,1.0,1200.0,1...|[0.11458541287952...|        1|                4.0|           4.0|                  4.0|             4.0|(13,[8],[1.0])|  (593,[17],[1.0])|       (585,[13],[1.0])|\n",
      "|    1|[1.0,1.0,1552.0,1...|[0.11458541287952...|        1|                5.0|           4.0|                  5.0|             4.0|(13,[6],[1.0])|  (593,[42],[1.0])|       (585,[15],[1.0])|\n",
      "|    1|[1.0,1.0,1655.0,1...|[0.11458541287952...|        1|                6.0|           4.0|                  5.0|             4.0|(13,[7],[1.0])|  (593,[18],[1.0])|       (585,[43],[1.0])|\n",
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_scaled = unionAll([c, not_c])\n",
    "training_data_scaled.show(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_ARRIVAL_TIME',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'B_DEPARTURE_TIME',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3302"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_scaled_no_hot.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-scaled: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_df.randomSplit(seed= 314, weights= [.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c2 = train_data.where(final_df.CANCELLED == 1)\n",
    "not_c2 = train_data.where(final_df.CANCELLED == 0).sample(False, 0.02, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1603"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_c2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = unionAll([c2, not_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|CANCELLED|count|\n",
      "+---------+-----+\n",
      "|        1| 1312|\n",
      "|        0| 1603|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy('CANCELLED').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_keep = [\n",
    " 'features_scaled',\n",
    " 'B_SCHEDULED_ARRIVAL',\n",
    " 'B_SCHEDULED_DEPARTURE',\n",
    " 'AIRLINE_Vec',\n",
    " 'ORIGIN_AIRPORT_Vec',\n",
    " 'DESTINATION_AIRPORT_Vec'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_ARRIVAL_TIME',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'B_DEPARTURE_TIME',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+\n",
      "|label|           features2|     features_scaled|row_index|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "|    1|[1.0,1.0,805.0,20...|[0.11458541287952...|    45566|\n",
      "|    1|[1.0,1.0,1200.0,7...|[0.11458541287952...|    45639|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_scaled_no_hot.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'label'\n",
    "positive_label = 1\n",
    "negative_label = 0\n",
    "\n",
    "SEED = 314\n",
    "ITERS = 10\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in vars_to_keep],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (assembler.transform(training_data_scaled).select(target, \"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: bigint, features: vector]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(1205,[0,1,2,3,4,...|\n",
      "|    1|(1205,[0,1,2,3,4,...|\n",
      "|    1|(1205,[0,1,2,3,4,...|\n",
      "|    1|(1205,[0,1,2,3,4,...|\n",
      "|    1|(1205,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=target, featuresCol=\"features\", maxIter=ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(gbt.maxIter, [1, 10]) \\\n",
    "            .addGrid(gbt.maxDepth, [1, 2]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "crossval = CrossValidator(\n",
    "            estimator=gbt, \n",
    "            estimatorParamMaps=paramGrid, \n",
    "            evaluator=evaluator, \n",
    "            numFolds=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part that returns error\n",
    "model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(assembler.transform(test_data_scaled.select(vars_to_keep)).select(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+---------+\n",
      "|label|           features2|     features_scaled|CANCELLED|B_SCHEDULED_ARRIVAL|B_ARRIVAL_TIME|B_SCHEDULED_DEPARTURE|B_DEPARTURE_TIME|   AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|row_index|\n",
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+---------+\n",
      "|    0|[1.0,1.0,505.0,50...|[0.11458541287952...|        0|                3.0|           3.0|                  1.0|             1.0|(13,[2],[1.0])|   (593,[6],[1.0])|        (585,[2],[1.0])|        0|\n",
      "|    0|[1.0,1.0,535.0,54...|[0.11458541287952...|        0|                2.0|           2.0|                  1.0|             1.0|(13,[4],[1.0])|  (593,[40],[1.0])|        (585,[1],[1.0])|        1|\n",
      "+-----+--------------------+--------------------+---------+-------------------+--------------+---------------------+----------------+--------------+------------------+-----------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_scaled.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe to an rdd. Then select only the prediction and feature fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|(1207,[0,1,2,3,4,...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|(1207,[0,1,2,3,4,...|[1.67697666691614...|[0.96623405454987...|       0.0|\n",
      "|(1207,[0,1,2,3,4,...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|(1207,[0,1,2,3,4,...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
      "|(1207,[0,1,2,3,4,...|[1.21914704037651...|[0.91970119430999...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.withColumn('row_index', F.monotonically_increasing_id())\n",
    "test_data_scaled = test_data_scaled.withColumn('row_index', F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scaled df and final_df\n",
    "tot_preds = predictions.join(test_data_scaled, predictions.row_index == test_data_scaled.row_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Test Error for GBT method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.011143\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"CANCELLED\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(tot_preds)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = DenseVector(model.bestModel.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTClassificationModel (uid=GBTClassifier_d5e32419c9f6) with 10 trees"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part doesn't seem to work. \n",
    "feat_imp = DenseVector(model.bestModel.featureImportances); feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pack variables, feature importances into pandas dataframe\n",
    "#df_feat_imp = pd.DataFrame(index=vars_to_keep2, columns=['feature_importance'], data=feat_imp[:])\n",
    "#df_feat_imp.sort_values(by='feature_importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_feat_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important variables in predicting wether a flight was cancelled are: Departure_Delay and Arrival_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cross validation to this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"CANCELLED\", outputCol=\"indexedLabel\").fit(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in vars_to_keep],\n",
    "                            outputCol='features')\n",
    "data = (assembler.transform(total_df).select(target, \"features\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+\n",
      "|label|           features2|     features_scaled|row_index|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "|    1|[1.0,4.0,200.0,13...|[0.11458541287952...|        0|\n",
      "|    0|[1.0,4.0,220.0,20...|[0.11458541287952...|        1|\n",
      "|    0|[1.0,4.0,545.0,60...|[0.11458541287952...|        2|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = trainingData.where(data.label == 1)\n",
    "not_c3 = trainingData.where(data.label == 0).sample(False, 0.025, 99)\n",
    "\n",
    "trainingData2 = unionAll([c3, not_c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "|    0|(1207,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"indexedFeatures\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "#labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "#pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'label'\n",
    "positive_label = 1\n",
    "negative_label = 0\n",
    "\n",
    "SEED = 314\n",
    "ITERS = 10\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = crossval.fit(trainingData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    0|(1207,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1207,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1207,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1207,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1207,[0,1,2,3,4,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0111926\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel (uid=RandomForestClassifier_ac9d9f81e22a) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
