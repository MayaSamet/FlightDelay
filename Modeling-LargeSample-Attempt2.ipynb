{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT and Random Forest Models: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file as dataframe \n",
    "# import pyspark modules\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, Bucketizer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "import functools \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"app\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .config('spark.cores.max', '2') \\\n",
    "    .config(\"spark.driver.memory\",'4g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(\"/home/jovyan/FlightDelay/clean_data_no_hot_2.dms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").option(\"inferschema\",\"true\").load(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>B_SCHEDULED_ARRIVAL</th>\n",
       "      <th>B_ARRIVAL_TIME</th>\n",
       "      <th>B_SCHEDULED_DEPARTURE</th>\n",
       "      <th>B_DEPARTURE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>840</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2296</td>\n",
       "      <td>806</td>\n",
       "      <td>811</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>1674</td>\n",
       "      <td>LAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>2174</td>\n",
       "      <td>803</td>\n",
       "      <td>753</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>136</td>\n",
       "      <td>ANC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1448</td>\n",
       "      <td>600</td>\n",
       "      <td>1476</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2459</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DFW</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>500</td>\n",
       "      <td>1476</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>B6</td>\n",
       "      <td>1990</td>\n",
       "      <td>SJU</td>\n",
       "      <td>EWR</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>512</td>\n",
       "      <td>516</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER ORIGIN_AIRPORT  \\\n",
       "0    0  2015      1    1            4      US            840            SFO   \n",
       "1    1  2015      1    1            4      AA           1674            LAS   \n",
       "2    2  2015      1    1            4      AS            136            ANC   \n",
       "3    3  2015      1    1            4      AA           2459            PHX   \n",
       "4    4  2015      1    1            4      B6           1990            SJU   \n",
       "\n",
       "  DESTINATION_AIRPORT  SCHEDULED_DEPARTURE        ...         DISTANCE  \\\n",
       "0                 CLT                   20        ...             2296   \n",
       "1                 MIA                   35        ...             2174   \n",
       "2                 SEA                  135        ...             1448   \n",
       "3                 DFW                  200        ...              868   \n",
       "4                 EWR                  206        ...             1608   \n",
       "\n",
       "   SCHEDULED_ARRIVAL  ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  \\\n",
       "0                806           811              5         0          0   \n",
       "1                803           753            -10         0          0   \n",
       "2                600          1476              4         0          1   \n",
       "3                500          1476              4         0          1   \n",
       "4                512           516              4         0          0   \n",
       "\n",
       "   B_SCHEDULED_ARRIVAL  B_ARRIVAL_TIME  B_SCHEDULED_DEPARTURE  \\\n",
       "0                  2.0             2.0                    0.0   \n",
       "1                  2.0             2.0                    0.0   \n",
       "2                  2.0             4.0                    0.0   \n",
       "3                  1.0             4.0                    0.0   \n",
       "4                  1.0             1.0                    0.0   \n",
       "\n",
       "   B_DEPARTURE_TIME  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               4.0  \n",
       "3               4.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder \n",
    "\n",
    "since vector type didn't transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"AIRLINE\", outputCol=\"AIRLINE_Index\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"AIRLINE_Index\", outputCol=\"AIRLINE_Vec\")\n",
    "encoded = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer2 = StringIndexer(inputCol=\"ORIGIN_AIRPORT\", outputCol=\"ORIGIN_AIRPORT_Index\")\n",
    "model2 = stringIndexer2.fit(encoded)\n",
    "indexed2 = model2.transform(encoded)\n",
    "\n",
    "encoder2 = OneHotEncoder(inputCol=\"ORIGIN_AIRPORT_Index\", outputCol=\"ORIGIN_AIRPORT_Vec\")\n",
    "encoded2 = encoder2.transform(indexed2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+-----------------------+\n",
      "|DESTINATION_AIRPORT|DESTINATION_AIRPORT_Index|DESTINATION_AIRPORT_Vec|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "|                CLT|                     14.0|       (618,[14],[1.0])|\n",
      "|                MIA|                     24.0|       (618,[24],[1.0])|\n",
      "|                SEA|                     10.0|       (618,[10],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                EWR|                     15.0|       (618,[15],[1.0])|\n",
      "|                CLT|                     14.0|       (618,[14],[1.0])|\n",
      "|                MCO|                     11.0|       (618,[11],[1.0])|\n",
      "|                JFK|                     18.0|       (618,[18],[1.0])|\n",
      "|                DEN|                      3.0|        (618,[3],[1.0])|\n",
      "|                ATL|                      0.0|        (618,[0],[1.0])|\n",
      "|                LAX|                      4.0|        (618,[4],[1.0])|\n",
      "|                IAH|                      5.0|        (618,[5],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                CLT|                     14.0|       (618,[14],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                DFW|                      2.0|        (618,[2],[1.0])|\n",
      "|                ATL|                      0.0|        (618,[0],[1.0])|\n",
      "|                FLL|                     22.0|       (618,[22],[1.0])|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer3 = StringIndexer(inputCol=\"DESTINATION_AIRPORT\", outputCol=\"DESTINATION_AIRPORT_Index\")\n",
    "model3 = stringIndexer3.fit(encoded2)\n",
    "indexed3 = model3.transform(encoded2)\n",
    "\n",
    "encoder3 = OneHotEncoder(inputCol=\"DESTINATION_AIRPORT_Index\", outputCol=\"DESTINATION_AIRPORT_Vec\")\n",
    "encoded3 = encoder3.transform(indexed3)\n",
    "encoded3.select('DESTINATION_AIRPORT','DESTINATION_AIRPORT_Index', \"DESTINATION_AIRPORT_Vec\").show()\n",
    "#encoded3.cache()b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_to_drop = ['AIRLINE_Index', 'AIRLINE', 'ORIGIN_AIRPORT_Index', \n",
    "                    'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT_Index',\n",
    "                    'DESTINATION_AIRPORT', 'FLIGHT_NUMBER']\n",
    "\n",
    "final_encoded = encoded3.drop(*new_cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'DEPARTURE_TIME',\n",
       " 'DEPARTURE_DELAY',\n",
       " 'SCHEDULED_TIME',\n",
       " 'ELAPSED_TIME',\n",
       " 'DISTANCE',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'ARRIVAL_TIME',\n",
       " 'ARRIVAL_DELAY',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_ARRIVAL_TIME',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'B_DEPARTURE_TIME',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = final_encoded.withColumn('CANCELLED2', final_encoded.CANCELLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_encoded.drop('_c0', 'YEAR', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'ARRIVAL_TIME', \n",
    "                              'B_ARRIVAL_TIME', 'ELAPSED_TIME', 'B_ARRIVAL_TIME', \n",
    "                              'B_DEPARTURE_TIME', 'DEPARTURE_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- B_SCHEDULED_ARRIVAL: double (nullable = true)\n",
      " |-- B_SCHEDULED_DEPARTURE: double (nullable = true)\n",
      " |-- AIRLINE_Vec: vector (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_Vec: vector (nullable = true)\n",
      " |-- DESTINATION_AIRPORT_Vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convery final_encoded to rdd \n",
    "# we cannpot scale bucketized or vec columns, so we omit those form the scaling process\n",
    "input_data = final_df.rdd.map(lambda x: (x[8], DenseVector(x[1:8])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, DenseVector([1.0, 4.0, 20.0, 286.0, 2296.0, 806.0, 0.0])),\n",
       " (0, DenseVector([1.0, 4.0, 35.0, 268.0, 2174.0, 803.0, 0.0])),\n",
       " (1, DenseVector([1.0, 4.0, 135.0, 205.0, 1448.0, 600.0, 0.0]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = sqlCtx.createDataFrame(input_data, [\"label\",\"features2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StandardScaler(inputCol = \"features2\", outputCol = \"features_scaled\")\n",
    "\n",
    "scaler = SS.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the data in df2 with our scaler \n",
    "scaled_df = scaler.transform(df2)\n",
    "#join scalable feature with columns  'AIRLINE_Vec', 'ORIGIN_AIRPORT_Vec', \n",
    "#'DESTINATION_AIRPORT_Vec', 'B_SCHEDULED_ARRIVAL', 'B_ARRIVAL_TIME', \n",
    "#'B_SCHEDULED_DEPARTURE','B_DEPARTURE_TIME'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|           features2|     features_scaled|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[1.0,4.0,20.0,286...|[0.11379250643083...|\n",
      "|    0|[1.0,4.0,35.0,268...|[0.11379250643083...|\n",
      "|    1|[1.0,4.0,135.0,20...|[0.11379250643083...|\n",
      "|    1|[1.0,4.0,200.0,12...|[0.11379250643083...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no common column between these two dataframes add row_index so that it can be joined\n",
    "scaled_df = scaled_df.withColumn('row_index', F.monotonically_increasing_id())\n",
    "final_df = final_df.withColumn('row_index', F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scaled df and final_df\n",
    "total_df = scaled_df.join(final_df, scaled_df.row_index == final_df.row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278016"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'row_index',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'SCHEDULED_TIME',\n",
       " 'DISTANCE',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec',\n",
       " 'row_index']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns of already scaled predictors \n",
    "total_df = total_df.drop(*['MONTH', 'DAY', 'DAY_OF_WEEK', 'SCHEDULED_DEPARTURE', 'SCHEDULED_TIME', 'DISTANCE',\n",
    "                           'SCHEDULED_ARRIVAL', 'DIVERTED', \n",
    "                           'CANCELLED2', 'row_index']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278016"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final scaled dataframe for predicting Cancelled flights \n",
    "total_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled: split data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_scaled, test_data_scaled) = total_df.randomSplit([0.8, 0.2], seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_data_scaled.where(total_df.label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to filter out large portion of non-canclelled flights in training data to make data more even \n",
    "not_c = train_data_scaled.where(total_df.label == 0).sample(False, .018, 454) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-236f07739693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnot_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \"\"\"\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "not_c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "|label|           features2|     features_scaled|CANCELLED|B_SCHEDULED_ARRIVAL|B_SCHEDULED_DEPARTURE|   AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|\n",
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "|    1|[2.0,1.0,1800.0,7...|[0.22758501286166...|        1|                6.0|                  6.0|(13,[8],[1.0])|  (614,[16],[1.0])|       (618,[12],[1.0])|\n",
      "|    1|[3.0,2.0,825.0,12...|[0.34137751929250...|        1|                3.0|                  2.0|(13,[0],[1.0])|   (614,[0],[1.0])|       (618,[20],[1.0])|\n",
      "|    1|[6.0,2.0,900.0,83...|[0.68275503858500...|        1|                3.0|                  3.0|(13,[8],[1.0])|  (614,[16],[1.0])|       (618,[21],[1.0])|\n",
      "|    1|[8.0,4.0,1710.0,1...|[0.91034005144667...|        1|                6.0|                  5.0|(13,[0],[1.0])|  (614,[44],[1.0])|       (618,[20],[1.0])|\n",
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data_scaled = unionAll([c, not_c])\n",
    "training_data_scaled.show(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'features2',\n",
       " 'features_scaled',\n",
       " 'CANCELLED',\n",
       " 'B_SCHEDULED_ARRIVAL',\n",
       " 'B_SCHEDULED_DEPARTURE',\n",
       " 'AIRLINE_Vec',\n",
       " 'ORIGIN_AIRPORT_Vec',\n",
       " 'DESTINATION_AIRPORT_Vec']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_scaled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_keep = [\n",
    " 'features_scaled',\n",
    " 'B_SCHEDULED_ARRIVAL',\n",
    " 'B_SCHEDULED_DEPARTURE',\n",
    " 'AIRLINE_Vec',\n",
    " 'ORIGIN_AIRPORT_Vec',\n",
    " 'DESTINATION_AIRPORT_Vec'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data_scaled_no_hot.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'label'\n",
    "positive_label = 1\n",
    "negative_label = 0\n",
    "\n",
    "SEED = 314\n",
    "ITERS = 10\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in vars_to_keep],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (assembler.transform(training_data_scaled).select(target, \"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: bigint, features: vector]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(1254,[0,1,2,3,4,...|\n",
      "|    1|(1254,[0,1,2,3,4,...|\n",
      "|    1|(1254,[0,1,2,3,4,...|\n",
      "|    1|(1254,[0,1,2,3,4,...|\n",
      "|    1|(1254,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=target, featuresCol=\"features\", maxIter=ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(gbt.maxIter, [1, 10]) \\\n",
    "            .addGrid(gbt.maxDepth, [1, 2]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "crossval = CrossValidator(\n",
    "            estimator=gbt, \n",
    "            estimatorParamMaps=paramGrid, \n",
    "            evaluator=evaluator, \n",
    "            numFolds=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part that returns error\n",
    "model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossValidatorModel_d5b8ef056e93"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(assembler.transform(test_data_scaled.select(vars_to_keep)).select(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "|label|           features2|     features_scaled|CANCELLED|B_SCHEDULED_ARRIVAL|B_SCHEDULED_DEPARTURE|   AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|\n",
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "|    0|[1.0,2.0,705.0,19...|[0.11379250643083...|        0|                4.0|                  2.0|(13,[2],[1.0])|   (614,[4],[1.0])|       (618,[14],[1.0])|\n",
      "|    0|[1.0,2.0,1022.0,1...|[0.11379250643083...|        0|                4.0|                  3.0|(13,[4],[1.0])|  (614,[11],[1.0])|      (618,[126],[1.0])|\n",
      "+-----+--------------------+--------------------+---------+-------------------+---------------------+--------------+------------------+-----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_scaled.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe to an rdd. Then select only the prediction and feature fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|(1254,[0,1,2,3,4,...|[0.12936935904792...|[0.56432621553613...|       0.0|\n",
      "|(1254,[0,1,2,3,4,...|[-0.0260722828258...|[0.48696681161706...|       1.0|\n",
      "|(1254,[0,1,2,3,4,...|[0.60117963212024...|[0.76894421757660...|       0.0|\n",
      "|(1254,[0,1,2,3,4,...|[0.06796111079743...|[0.53392833639751...|       0.0|\n",
      "|(1254,[0,1,2,3,4,...|[-0.0701705668954...|[0.46497218893408...|       1.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions.withColumn('row_index', F.monotonically_increasing_id())\n",
    "test_data_scaled = test_data_scaled.withColumn('row_index', F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scaled df and final_df\n",
    "tot_preds = predictions.join(test_data_scaled, predictions.row_index == test_data_scaled.row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+-----------+-----+--------------------+--------------------+---------+-------------------+---------------------+---------------+------------------+-----------------------+-----------+\n",
      "|            features|       rawPrediction|         probability|prediction|  row_index|label|           features2|     features_scaled|CANCELLED|B_SCHEDULED_ARRIVAL|B_SCHEDULED_DEPARTURE|    AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|  row_index|\n",
      "+--------------------+--------------------+--------------------+----------+-----------+-----+--------------------+--------------------+---------+-------------------+---------------------+---------------+------------------+-----------------------+-----------+\n",
      "|(1254,[0,1,2,3,4,...|[-0.1138986851704...|[0.44329565241512...|       1.0|         26|    0|[5.0,1.0,1907.0,6...|[0.56896253215417...|        0|                6.0|                  6.0| (13,[4],[1.0])| (614,[390],[1.0])|       (618,[70],[1.0])|         26|\n",
      "|(1254,[0,1,2,3,4,...|[0.10210275008952...|[0.55087470866043...|       0.0|         29|    0|[5.0,6.0,1102.0,3...|[0.56896253215417...|        0|                3.0|                  3.0|(13,[12],[1.0])|  (614,[35],[1.0])|       (618,[87],[1.0])|         29|\n",
      "|(1254,[0,1,2,3,4,...|[0.54600517956151...|[0.74876009627451...|       0.0| 8589934658|    0|[8.0,1.0,1105.0,1...|[0.91034005144667...|        0|                4.0|                  3.0| (13,[1],[1.0])|  (614,[15],[1.0])|        (618,[7],[1.0])| 8589934658|\n",
      "|(1254,[0,1,2,3,4,...|[0.10210275008952...|[0.55087470866043...|       0.0|34359738398|    0|[3.0,6.0,1215.0,6...|[0.34137751929250...|        0|                4.0|                  4.0| (13,[3],[1.0])| (614,[387],[1.0])|       (618,[17],[1.0])|34359738398|\n",
      "|(1254,[0,1,2,3,4,...|[-0.0161683392391...|[0.49191653474835...|       1.0|42949673263|    1|[28.0,2.0,527.0,4...|[3.18619018006337...|        1|                2.0|                  1.0| (13,[3],[1.0])|  (614,[45],[1.0])|        (618,[1],[1.0])|42949673263|\n",
      "+--------------------+--------------------+--------------------+----------+-----------+-----+--------------------+--------------------+---------+-------------------+---------------------+---------------+------------------+-----------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tot_preds.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaliuation for GBT method \n",
    "\n",
    "Model Evaluation: For classification, this would include: i. accuracy ii. precision, recall, F1 score ii. confusion matrix iv. area under ROC curve (AUROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.190571\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"CANCELLED\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(tot_preds)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under the curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation (area under ROC): 0.809429\n"
     ]
    }
   ],
   "source": [
    "print(\"evaluation (area under ROC): %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = TP / (TP+FP) \n",
    "\n",
    "Recall = TP / (TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = df[(df.target_index == 1) & (df.prediction == 1)].count()\n",
    "tp = tot_preds[(tot_preds.label == 1) & (tot_preds.prediction == 1)].count()\n",
    "tn = tot_preds[(tot_preds.label == 0) & (tot_preds.prediction == 0)].count()\n",
    "fp = tot_preds[(tot_preds.label == 0) & (tot_preds.prediction == 1)].count()\n",
    "fn = tot_preds[(tot_preds.label == 1) & (tot_preds.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 432\n",
      "True Negatives: 44467\n",
      "False Positives: 10082\n",
      "False Negatives: 489\n",
      "Total 278016\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix \n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"Total\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and recall: \n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.0410881\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision = %g\" % (precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.469055\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall = %g\" % (recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTClassificationModel (uid=GBTClassifier_b5b67696efe6) with 10 trees"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cross validation to this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"CANCELLED\", outputCol=\"indexedLabel\").fit(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "                            inputCols=[c for c in vars_to_keep],\n",
    "                            outputCol='features')\n",
    "data = (assembler.transform(total_df).select(target, \"features\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+---------+\n",
      "|label|           features2|     features_scaled|row_index|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "|    0|[1.0,4.0,20.0,286...|[0.11379250643083...|        0|\n",
      "|    0|[1.0,4.0,35.0,268...|[0.11379250643083...|        1|\n",
      "|    1|[1.0,4.0,135.0,20...|[0.11379250643083...|        2|\n",
      "+-----+--------------------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed = 314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = trainingData.where(data.label == 1)\n",
    "not_c3 = trainingData.where(data.label == 0).sample(False, 0.018, 99)\n",
    "\n",
    "trainingData2 = unionAll([c3, not_c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "|    0|(1254,[0,1,2,3,4,...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"indexedFeatures\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'label'\n",
    "positive_label = 1\n",
    "negative_label = 0\n",
    "\n",
    "SEED = 314\n",
    "ITERS = 10\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = crossval.fit(trainingData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    0|(1254,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1254,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1254,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1254,[0,1,2,3,4,...|\n",
      "|       0.0|    0|(1254,[0,1,2,3,4,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.175717\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area Under the Curve: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation (area under ROC): 0.824283\n"
     ]
    }
   ],
   "source": [
    "print(\"evaluation (area under ROC): %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = df[(df.target_index == 1) & (df.prediction == 1)].count()\n",
    "tp = predictions[(predictions.label == 1) & (predictions.prediction == 1)].count()\n",
    "tn = predictions[(predictions.label == 0) & (predictions.prediction == 0)].count()\n",
    "fp = predictions[(predictions.label == 0) & (predictions.prediction == 1)].count()\n",
    "fn = predictions[(predictions.label == 1) & (predictions.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 371\n",
      "True Negatives: 45352\n",
      "False Positives: 9197\n",
      "False Negatives: 550\n",
      "Total 278016\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix \n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"Total\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision and recall: \n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.0387751\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision = %g\" % (precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.402823\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall = %g\" % (recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
