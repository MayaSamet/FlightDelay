{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Column Descriptions! \n",
    "\n",
    "YEAR Year of the Flight Trip \n",
    "\n",
    "MONTH Month of the Flight Trip\n",
    "\n",
    "DAY Day of the Flight Trip \n",
    "\n",
    "DAY_OF_WEEK Day of week of the Flight Trip\n",
    "\n",
    "AIRLINE Airline Identifier\n",
    "\n",
    "FLIGHT_NUMBER Flight Identifier\n",
    "\n",
    "TAIL_NUMBER Aircraft Identifier\n",
    "\n",
    "ORIGIN_AIRPORT Starting Airport\n",
    "\n",
    "DESTINATION_AIRPORT  Destination Airport\n",
    "\n",
    "SCHEDULED_DEPARTURE  Planned Departure Time\n",
    "\n",
    "DEPARTURE_TIMEWHEEL_OFF - TAXI_OUT\n",
    "\n",
    "DEPARTURE_DELAY  Total Delay on Departure\n",
    "\n",
    "TAXI_OUT The time duration elapsed between departure from the origin airport gate and wheels off\n",
    "\n",
    "WHEELS_OFFThe time point that the aircraft's wheels leave the ground\n",
    "\n",
    "SCHEDULED_TIMEPlanned time amount needed for the flight trip\n",
    "\n",
    "ELAPSED_TIMEAIR_TIME+TAXI_IN+TAXI_OUT\n",
    "\n",
    "AIR_TIMEThe time duration between wheels_off and wheels_on time\n",
    "\n",
    "DISTANCEDistance between two airports\n",
    "\n",
    "WHEELS_ON The time point that the aircraft's wheels touch on the ground\n",
    "\n",
    "TAXI_IN The time duration elapsed between wheels-on and gate arrival at the destination airport\n",
    "\n",
    "SCHEDULED_ARRIVAL Planned arrival time\n",
    "\n",
    "ARRIVAL_TIMEWHEELS_ON+TAXI_IN\n",
    "\n",
    "ARRIVAL_DELAY \n",
    "\n",
    "ARRIVAL_TIME-SCHEDULED_ARRIVAL\n",
    "\n",
    "DIVERTED Aircraft landed on airport that out of schedule\n",
    "\n",
    "CANCELLED Flight Cancelled (1 = cancelled)\n",
    "\n",
    "CANCELLATION_REASON Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National Air System; D - Security\n",
    "\n",
    "AIR_SYSTEM_DELAY Delay caused by air system\n",
    "\n",
    "SECURITY_DELAY Delay caused by security\n",
    "\n",
    "AIRLINE_DELAY Delay caused by the airline\n",
    "\n",
    "LATE_AIRCRAFT_DELAY Delay caused by aircraft\n",
    "\n",
    "WEATHER_DELAY Delay caused by weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file as dataframe \n",
    "# import pyspark modules\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"app\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .config('spark.cores.max', '2') \\\n",
    "    .config(\"spark.driver.memory\",'4g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of APT edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(\"/home/jovyan/FlightDelay/flights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_rdd = sc.textFile(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delay_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferschema\",\"true\").load(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5819079"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowcount=delay_df.count()\n",
    "rowcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|  DEPARTURE_DELAY|    ARRIVAL_DELAY|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|          5732926|          5714008|\n",
      "|   mean|9.370158275198389|4.407057357987598|\n",
      "| stddev|37.08094249678714|39.27129709388608|\n",
      "|    min|              -82|              -87|\n",
      "|    max|             1988|             1971|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.describe(['DEPARTURE_DELAY', 'ARRIVAL_DELAY']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows = 5819079\n"
     ]
    }
   ],
   "source": [
    "print('rows = {}'.format(rowcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows = 5819079\n"
     ]
    }
   ],
   "source": [
    "print('rows = {}'.format(delay_df.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears there are no duplicated entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+--------------------+--------------------+----------------------+--------------------+--------------------+----------------+-------------------+-------------------+-------------------------+--------------------+---------------------+----------------+-----------------+\n",
      "|YEAR_missing|MONTH_missing|DAY_missing|DAY_OF_WEEK_missing|AIRLINE_missing|FLIGHT_NUMBER_missing| TAIL_NUMBER_missing|ORIGIN_AIRPORT_missing|DESTINATION_AIRPORT_missing|SCHEDULED_DEPARTURE_missing|DEPARTURE_TIME_missing|DEPARTURE_DELAY_missing|    TAXI_OUT_missing|  WHEELS_OFF_missing|SCHEDULED_TIME_missing|ELAPSED_TIME_missing|    AIR_TIME_missing|DISTANCE_missing|  WHEELS_ON_missing|    TAXI_IN_missing|SCHEDULED_ARRIVAL_missing|ARRIVAL_TIME_missing|ARRIVAL_DELAY_missing|DIVERTED_missing|CANCELLED_missing|\n",
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+--------------------+--------------------+----------------------+--------------------+--------------------+----------------+-------------------+-------------------+-------------------------+--------------------+---------------------+----------------+-----------------+\n",
      "|         0.0|          0.0|        0.0|                0.0|            0.0|                  0.0|0.002529781774744...|                   0.0|                        0.0|                        0.0|  0.014805263857046835|   0.014805263857046835|0.015302593417274468|0.015302593417274468|  1.031091002579032E-6|0.018056293788071942|0.018056293788071942|             0.0|0.01589822031974475|0.01589822031974475|                      0.0| 0.01589822031974475| 0.018056293788071942|             0.0|              0.0|\n",
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+--------------------+--------------------+----------------------+--------------------+--------------------+----------------+-------------------+-------------------+-------------------------+--------------------+---------------------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculates percent of missing values in ecah column! \n",
    "missing = delay_df.agg(*[\n",
    "    (1-F.count(c) / F.count('*')).alias(c + '_missing')\n",
    "    for c in delay_df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 6 columns appear to have very large percentage of missing values: \n",
    "\n",
    "# Lauren - where do you see this?\n",
    "\n",
    "CANCELLATION_REASON_missing, AIR_SYSTEM_DELAY_missing, SECURITY_DELAY_missing, \n",
    "AIRLINE_DELAY_missing, LATE_AIRCRAFT_DELAY_missing, WEATHER_DELAY_missing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I drop all of these columns? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['WEATHER_DELAY', 'SECURITY_DELAY', 'AIR_SYSTEM_DELAY','AIRLINE_DELAY', \n",
    "                'LATE_AIRCRAFT_DELAY', 'CANCELLATION_REASON'] \n",
    "\n",
    "delay_df = delay_df.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records where at least 3 columns have NULL values \n",
    "\n",
    "delay_df = delay_df.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't change the count of the DF, so no rows with atleast 3 missing columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5819079"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = cols_to_exclude = ['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK',\n",
    "                   'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DIVERTED', \n",
    "                   'CANCELLED', 'DESTINATION_AIRPORT', 'AIRLINE', \n",
    "                   'FLIGHT_NUMBER', 'TAIL_NUMBER']\n",
    "\n",
    "\n",
    "df_impute = delay_df.drop(*drop_cols)\n",
    "means = df_impute.agg(*[F.mean(c).alias(c) \\\n",
    "                                for c in df_impute.columns]) \\\n",
    "                                .toPandas().to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = ['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK',\n",
    "                   'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DIVERTED', \n",
    "                   'CANCELLED', 'DESTINATION_AIRPORT', 'AIRLINE', \n",
    "                   'FLIGHT_NUMBER', 'TAIL_NUMBER'] \n",
    "\n",
    "df_for_outlier_calc = delay_df.drop(*cols_to_exclude)\n",
    "\n",
    "cols = [c for c in df_for_outlier_calc.columns]\n",
    "bounds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6d0be8709adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquantiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_for_outlier_calc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxQuantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mIQR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     bounds[col] = [\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mapproxQuantile\u001b[0;34m(self, col, probabilities, relativeError)\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mrelativeError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelativeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1884\u001b[0;31m         \u001b[0mjaq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxQuantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelativeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1885\u001b[0m         \u001b[0mjaq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjaq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjaq_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misStr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjaq_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    quantiles = df_for_outlier_calc.approxQuantile(col, [0.25, 0.75], 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    \n",
    "    bounds[col] = [\n",
    "        quantiles[0] - 1.5 * IQR,\n",
    "        quantiles[1] + 1.5 * IQR\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append outlier indicator to data table \\\n",
    "\n",
    "outliers = df_for_outlier_calc.select(*['TAIL_NUMBER'] + [\n",
    " (\n",
    " (df_for_outlier_calc[c] < bounds[c][0]) | (df_for_outlier_calc[c] > bounds[c][1]))\n",
    "    .alias(c + '_outlier') for c in cols\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketizer (practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(numbers=-999.9),\n",
       " Row(numbers=-0.5),\n",
       " Row(numbers=-0.3),\n",
       " Row(numbers=0.0),\n",
       " Row(numbers=0.2),\n",
       " Row(numbers=999.9)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql import Row\n",
    "\n",
    "splits = [-9999999, -0.5, 0.0, 0.5, 9999999]\n",
    "\n",
    "data = [-999.9, -0.5, -0.3, 0.0, 0.2, 999.9]\n",
    "\n",
    "data= list(map(lambda x: Row(numbers=x), data))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = sqlCtx.createDataFrame(data, [\"numbers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketizer output with ${bucketizer.getSplits.length-1} buckets\n",
      "+-------+----------------+\n",
      "|numbers|bucketedFeatures|\n",
      "+-------+----------------+\n",
      "| -999.9|             0.0|\n",
      "|   -0.5|             1.0|\n",
      "|   -0.3|             1.0|\n",
      "|    0.0|             2.0|\n",
      "|    0.2|             2.0|\n",
      "|  999.9|             3.0|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucketizer = Bucketizer() \\\n",
    "  .setInputCol(\"numbers\") \\\n",
    "  .setOutputCol(\"bucketedFeatures\") \\\n",
    "  .setSplits(splits)\n",
    "\n",
    "\n",
    "#Transform original data into its bucket index.\n",
    "bucketedData = bucketizer.transform(dataFrame)\n",
    "\n",
    "print(\"Bucketizer output with ${bucketizer.getSplits.length-1} buckets\")\n",
    "bucketedData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketizer (application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+------------+--------------+\n",
      "|DEPARTURE_TIME|SCHEDULED_DEPARTURE|ARRIVAL_TIME|SCHEDULED_TIME|\n",
      "+--------------+-------------------+------------+--------------+\n",
      "|          2354|                  5|         408|           205|\n",
      "|             2|                 10|         741|           280|\n",
      "|            18|                 20|         811|           286|\n",
      "|            15|                 20|         756|           285|\n",
      "|            24|                 25|         259|           235|\n",
      "|            20|                 25|         610|           217|\n",
      "|            19|                 25|         509|           181|\n",
      "|            44|                 30|         753|           273|\n",
      "|            19|                 30|         532|           195|\n",
      "|            33|                 30|         656|           221|\n",
      "+--------------+-------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.select([\"DEPARTURE_TIME\", \"SCHEDULED_DEPARTURE\", \"ARRIVAL_TIME\", \"SCHEDULED_TIME\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_splits = [0, 300, 600, 900, 1200, 1500, 1800, 2100, 2400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the job, quickly too, but not very elegantly. Look into how to bucketize groups of columns\n",
    "\n",
    "deptime_bucketizer = Bucketizer() \\\n",
    "  .setInputCol(\"DEPARTURE_TIME\") \\\n",
    "  .setOutputCol(\"B_DEPARTURE_TIME\") \\\n",
    "  .setSplits(delay_splits)\n",
    "\n",
    "scheddep_bucketizer = Bucketizer() \\\n",
    "  .setInputCol(\"SCHEDULED_DEPARTURE\") \\\n",
    "  .setOutputCol(\"B_SCHEDULED_DEPARTURE\") \\\n",
    "  .setSplits(delay_splits)\n",
    "\n",
    "arrtime_bucketizer = Bucketizer() \\\n",
    "  .setInputCol(\"ARRIVAL_TIME\") \\\n",
    "  .setOutputCol(\"B_ARRIVAL_TIME\") \\\n",
    "  .setSplits(delay_splits)\n",
    "\n",
    "schedarr_bucketizer = Bucketizer() \\\n",
    "  .setInputCol(\"SCHEDULED_ARRIVAL\") \\\n",
    "  .setOutputCol(\"B_SCHEDULED_ARRIVAL\") \\\n",
    "  .setSplits(delay_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform original data into its bucket index.\n",
    "delay_df_b = deptime_bucketizer\\\n",
    "               .transform(scheddep_bucketizer\\\n",
    "               .transform(arrtime_bucketizer\\\n",
    "               .transform(schedarr_bucketizer\\\n",
    "               .transform(delay_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+--------------+-------------------+\n",
      "|B_DEPARTURE_TIME|B_SCHEDULED_DEPARTURE|B_ARRIVAL_TIME|B_SCHEDULED_ARRIVAL|\n",
      "+----------------+---------------------+--------------+-------------------+\n",
      "|             7.0|                  0.0|           1.0|                1.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "|             0.0|                  0.0|           0.0|                1.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "|             0.0|                  0.0|           1.0|                1.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "|             0.0|                  0.0|           1.0|                1.0|\n",
      "|             0.0|                  0.0|           2.0|                2.0|\n",
      "+----------------+---------------------+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df_b.select([\"B_DEPARTURE_TIME\", \"B_SCHEDULED_DEPARTURE\", \"B_ARRIVAL_TIME\", \"B_SCHEDULED_ARRIVAL\"]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
