{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Column Descriptions! \n",
    "\n",
    "YEAR Year of the Flight Trip \n",
    "\n",
    "MONTH Month of the Flight Trip\n",
    "\n",
    "DAY Day of the Flight Trip \n",
    "\n",
    "DAY_OF_WEEK Day of week of the Flight Trip\n",
    "\n",
    "AIRLINE Airline Identifier\n",
    "\n",
    "FLIGHT_NUMBER Flight Identifier\n",
    "\n",
    "TAIL_NUMBER Aircraft Identifier\n",
    "\n",
    "ORIGIN_AIRPORT Starting Airport\n",
    "\n",
    "DESTINATION_AIRPORT  Destination Airport\n",
    "\n",
    "SCHEDULED_DEPARTURE  Planned Departure Time\n",
    "\n",
    "DEPARTURE_TIME: WHEEL_OFF - TAXI_OUT\n",
    "\n",
    "DEPARTURE_DELAY  Total Delay on Departure\n",
    "\n",
    "TAXI_OUT The time duration elapsed between departure from the origin airport gate and wheels off\n",
    "\n",
    "WHEELS_OFF The time point that the aircraft's wheels leave the ground\n",
    "\n",
    "SCHEDULED_TIME: Planned time amount needed for the flight trip\n",
    "\n",
    "ELAPSED_TIME:  AIR_TIME + TAXI_IN + TAXI_OUT\n",
    "\n",
    "AIR_TIME The time duration between wheels_off and wheels_on time\n",
    "\n",
    "DISTANCE Distance between two airports\n",
    "\n",
    "WHEELS_ON The time point that the aircraft's wheels touch on the ground\n",
    "\n",
    "TAXI_IN The time duration elapsed between wheels-on and gate arrival at the destination airport\n",
    "\n",
    "SCHEDULED_ARRIVAL Planned arrival time\n",
    "\n",
    "ARRIVAL_TIME:  WHEELS_ON + TAXI_IN\n",
    "\n",
    "ARRIVAL_DELAY: ARRIVAL_TIME - SCHEDULED_ARRIVAL\n",
    "\n",
    "DIVERTED Aircraft landed on airport that out of schedule\n",
    "\n",
    "CANCELLED Flight Cancelled (1 = cancelled)\n",
    "\n",
    "CANCELLATION_REASON Reason for Cancellation of flight: A - Airline/Carrier; B - Weather; C - National Air System; D - Security\n",
    "\n",
    "AIR_SYSTEM_DELAY Delay caused by air system\n",
    "\n",
    "SECURITY_DELAY Delay caused by security\n",
    "\n",
    "AIRLINE_DELAY Delay caused by the airline\n",
    "\n",
    "LATE_AIRCRAFT_DELAY Delay caused by aircraft\n",
    "\n",
    "WEATHER_DELAY Delay caused by weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in file as dataframe \n",
    "# import pyspark modules\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *       # for datatype conversion\n",
    "from pyspark.sql.functions import *   # for col() function\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"app\") \\\n",
    "    .config(\"spark.executor.memory\", '2g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .config('spark.cores.max', '2') \\\n",
    "    .config(\"spark.driver.memory\",'4g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of APT edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = os.path.join(\"/home/jovyan/FlightDelay/flights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_rdd = sc.textFile(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delay_rdd.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").option(\"inferschema\",\"true\").load(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[YEAR: int, MONTH: int, DAY: int, DAY_OF_WEEK: int, AIRLINE: string, FLIGHT_NUMBER: int, TAIL_NUMBER: string, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: int, DEPARTURE_TIME: int, DEPARTURE_DELAY: int, TAXI_OUT: int, WHEELS_OFF: int, SCHEDULED_TIME: int, ELAPSED_TIME: int, AIR_TIME: int, DISTANCE: int, WHEELS_ON: int, TAXI_IN: int, SCHEDULED_ARRIVAL: int, ARRIVAL_TIME: int, ARRIVAL_DELAY: int, DIVERTED: int, CANCELLED: int, CANCELLATION_REASON: string, AIR_SYSTEM_DELAY: int, SECURITY_DELAY: int, AIRLINE_DELAY: int, LATE_AIRCRAFT_DELAY: int, WEATHER_DELAY: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.show(3)\n",
    "delay_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = true)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
      " |-- SECURITY_DELAY: integer (nullable = true)\n",
      " |-- AIRLINE_DELAY: integer (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
      " |-- WEATHER_DELAY: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5287214"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|   DEPARTURE_DELAY|     ARRIVAL_DELAY|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           5208890|           5191895|\n",
      "|   mean|  9.17736811489588| 4.284605717180336|\n",
      "| stddev|36.605655917829274|38.808542303886945|\n",
      "|    min|               -68|               -87|\n",
      "|    max|              1988|              1971|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.describe(['DEPARTURE_DELAY', 'ARRIVAL_DELAY']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows = 5287214\n"
     ]
    }
   ],
   "source": [
    "print('rows = {}'.format(delay_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows = 5287214\n"
     ]
    }
   ],
   "source": [
    "print('rows = {}'.format(delay_df.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears there are no duplicated entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+-------------------+-------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+------------------------+----------------------+---------------------+---------------------------+---------------------+\n",
      "|YEAR_missing|MONTH_missing|DAY_missing|DAY_OF_WEEK_missing|AIRLINE_missing|FLIGHT_NUMBER_missing| TAIL_NUMBER_missing|ORIGIN_AIRPORT_missing|DESTINATION_AIRPORT_missing|SCHEDULED_DEPARTURE_missing|DEPARTURE_TIME_missing|DEPARTURE_DELAY_missing|   TAXI_OUT_missing| WHEELS_OFF_missing|SCHEDULED_TIME_missing|ELAPSED_TIME_missing|    AIR_TIME_missing|    DISTANCE_missing|   WHEELS_ON_missing|     TAXI_IN_missing|SCHEDULED_ARRIVAL_missing|ARRIVAL_TIME_missing|ARRIVAL_DELAY_missing|    DIVERTED_missing|   CANCELLED_missing|CANCELLATION_REASON_missing|AIR_SYSTEM_DELAY_missing|SECURITY_DELAY_missing|AIRLINE_DELAY_missing|LATE_AIRCRAFT_DELAY_missing|WEATHER_DELAY_missing|\n",
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+-------------------+-------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+------------------------+----------------------+---------------------+---------------------------+---------------------+\n",
      "|         0.0|          0.0|        0.0|                0.0|            0.0|                  0.0|0.002560895019569...|  1.891355257965798...|       1.891355257965798...|       1.891355257965798...|  0.014813850924135119|   0.014813850924135119|0.01530673810441563|0.01530673810441563|  1.323948680687081...|0.018028209185404598|0.018028209185404598|1.891355257965798...|0.015864498770051694|0.015864498770051694|     1.891355257965798...|0.015864498770051694| 0.018028209185404598|1.891355257965798...|1.891355257965798...|         0.9845565169104182|      0.8188295385811886|    0.8188295385811886|   0.8188295385811886|         0.8188295385811886|   0.8188295385811886|\n",
      "+------------+-------------+-----------+-------------------+---------------+---------------------+--------------------+----------------------+---------------------------+---------------------------+----------------------+-----------------------+-------------------+-------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+------------------------+----------------------+---------------------+---------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculates percent of missing values in ecah column! \n",
    "missing = delay_df.agg(*[\n",
    "    (1-F.count(c) / F.count('*')).alias(c + '_missing')\n",
    "    for c in delay_df.columns\n",
    "]).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 6 coluns appear to have very large percentage of missing values: \n",
    "\n",
    "CANCELLATION_REASON_missing, AIR_SYSTEM_DELAY_missing, SECURITY_DELAY_missing, \n",
    "AIRLINE_DELAY_missing, LATE_AIRCRAFT_DELAY_missing, WEATHER_DELAY_missing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I drop all of these columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+----------------+-------------+-------------------+-------------------+\n",
      "|WEATHER_DELAY|SECURITY_DELAY|AIR_SYSTEM_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|CANCELLATION_REASON|\n",
      "+-------------+--------------+----------------+-------------+-------------------+-------------------+\n",
      "|         null|          null|            null|         null|               null|               null|\n",
      "|         null|          null|            null|         null|               null|               null|\n",
      "|         null|          null|            null|         null|               null|               null|\n",
      "|         null|          null|            null|         null|               null|               null|\n",
      "|         null|          null|            null|         null|               null|               null|\n",
      "+-------------+--------------+----------------+-------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.select('WEATHER_DELAY', 'SECURITY_DELAY', 'AIR_SYSTEM_DELAY', \n",
    "                'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'CANCELLATION_REASON').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns selected have almost 90% na, so I'm dropping them from the dataet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['WEATHER_DELAY', 'SECURITY_DELAY', 'AIR_SYSTEM_DELAY','AIRLINE_DELAY', \n",
    "                'LATE_AIRCRAFT_DELAY', 'CANCELLATION_REASON', 'WHEELS_ON', 'WHEELS_OFF', \n",
    "                'TAXI_IN', 'TAXI_OUT', 'AIR_TIME', 'TAIL_NUMBER'] \n",
    "\n",
    "delay_df = delay_df.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records where atleast 3 columns have NULL values \n",
    "\n",
    "delay_df = delay_df.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't change the count of the DF, so no rows with atleast 3 missing columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5287214"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', 'DIVERTED', \n",
    "                   'CANCELLED', 'DESTINATION_AIRPORT', 'AIRLINE']\n",
    "\n",
    "\n",
    "df_impute = delay_df.drop(*drop_cols)\n",
    "means = df_impute.agg(*[F.mean(c).alias(c) \\\n",
    "                                for c in df_impute.columns]) \\\n",
    "                                .toPandas().to_dict('records')[0]\n",
    "\n",
    "df_impute_mode = delay_df.select('YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'ORIGIN_AIRPORT', \n",
    "                                 'DIVERTED','CANCELLED', 'DESTINATION_AIRPORT', 'AIRLINE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = []\n",
    "for c in df_impute_mode.columns:\n",
    "    df=df_impute_mode.groupBy(c).count()\n",
    "    mode = df.orderBy(df['count'].desc()).collect()[0][0]\n",
    "    modes.append((c,mode))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turn list of tuples to dictionary \n",
    "modes = dict(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dictionaries\n",
    "def Merge(dict1, dict2): \n",
    "    res = {**dict1, **dict2} \n",
    "    return res \n",
    "\n",
    "imputed_vals = Merge(means,modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to impute values for these columns since I dont know how imputing integer values such as day of the week or year will affect the data. We can ask the professor about this! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FLIGHT_NUMBER': 2174.2944622631126,\n",
       " 'SCHEDULED_DEPARTURE': 1329.220278392363,\n",
       " 'DEPARTURE_TIME': 1334.862200773413,\n",
       " 'DEPARTURE_DELAY': 9.174740610083118,\n",
       " 'SCHEDULED_TIME': 141.357636933175,\n",
       " 'ELAPSED_TIME': 136.72784381339585,\n",
       " 'DISTANCE': 820.9152375901562,\n",
       " 'SCHEDULED_ARRIVAL': 1494.5158332914084,\n",
       " 'ARRIVAL_TIME': 1476.9633466699097,\n",
       " 'ARRIVAL_DELAY': 4.279474785775647,\n",
       " 'YEAR': 2015,\n",
       " 'MONTH': 7,\n",
       " 'DAY': 2,\n",
       " 'DAY_OF_WEEK': 5,\n",
       " 'ORIGIN_AIRPORT': 'ATL',\n",
       " 'DIVERTED': 0,\n",
       " 'CANCELLED': 0,\n",
       " 'DESTINATION_AIRPORT': 'ATL',\n",
       " 'AIRLINE': 'WN'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of means to impute \n",
    "imputed_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill na values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'AIRLINE',\n",
       " 'ORIGIN_AIRPORT',\n",
       " 'DESTINATION_AIRPORT',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'DEPARTURE_TIME',\n",
       " 'DEPARTURE_DELAY',\n",
       " 'SCHEDULED_TIME',\n",
       " 'ELAPSED_TIME',\n",
       " 'DISTANCE',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'ARRIVAL_TIME',\n",
       " 'ARRIVAL_DELAY',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delay_df = delay_df.fillna(imputed_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+---------------+---------+--------------+------------+-------------+\n",
      "|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|CANCELLED|SCHEDULED_TIME|ARRIVAL_TIME|ARRIVAL_DELAY|\n",
      "+-------------------+--------------+---------------+---------+--------------+------------+-------------+\n",
      "|                  5|          2354|            -11|        0|           205|         408|          -22|\n",
      "|                 25|            24|             -1|        0|           235|         259|          -21|\n",
      "|                 25|            19|             -6|        0|           181|         509|          -17|\n",
      "|                 30|            19|            -11|        0|           195|         532|          -13|\n",
      "|                 30|            24|             -6|        0|           173|         453|          -30|\n",
      "+-------------------+--------------+---------------+---------+--------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.select('SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', \n",
    "                'DEPARTURE_DELAY','CANCELLED', \n",
    "                'SCHEDULED_TIME', 'ARRIVAL_TIME', 'ARRIVAL_DELAY').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|ORIGIN_AIRPORT|DESTINATION_AIRPORT|\n",
      "+--------------+-------------------+\n",
      "|           ANC|                SEA|\n",
      "|           LAX|                PBI|\n",
      "|           SFO|                CLT|\n",
      "|           LAX|                MIA|\n",
      "|           SEA|                ANC|\n",
      "|           SFO|                MSP|\n",
      "|           LAS|                MSP|\n",
      "|           LAX|                CLT|\n",
      "|           SFO|                DFW|\n",
      "|           LAS|                ATL|\n",
      "+--------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_df.select('ORIGIN_AIRPORT', 'DESTINATION_AIRPORT').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[YEAR: int, MONTH: int, DAY: int, DAY_OF_WEEK: int, AIRLINE: string, FLIGHT_NUMBER: int, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: int, DEPARTURE_TIME: int, DEPARTURE_DELAY: int, SCHEDULED_TIME: int, ELAPSED_TIME: int, DISTANCE: int, SCHEDULED_ARRIVAL: int, ARRIVAL_TIME: int, ARRIVAL_DELAY: int, DIVERTED: int, CANCELLED: int]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables with potentially influential outlier values \n",
    "df_for_outlier_calc = delay_df.select('DEPARTURE_DELAY', 'ARRIVAL_DELAY', \n",
    "                                      'ELAPSED_TIME', 'DISTANCE')\n",
    "\n",
    "cols = [c for c in df_for_outlier_calc.columns]\n",
    "bounds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Since we have a large amount of outliers, change settings to 2.0 * IQR to capture more of our data.\n",
    "for col in cols:\n",
    "    quantiles = df_for_outlier_calc.approxQuantile(col, [0.25, 0.75], 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    \n",
    "    bounds[col] = [\n",
    "        quantiles[0] - 3.3 * IQR,\n",
    "        quantiles[1] + 3.3 * IQR\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#append outlier indicator to data table \\\n",
    "\n",
    "outliers = df_for_outlier_calc.select([\n",
    " (\n",
    " (df_for_outlier_calc[c] < bounds[c][0]) | (df_for_outlier_calc[c] > bounds[c][1]))\n",
    "    .alias(c + '_outlier') for c in cols\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Outlier approach: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate values used for outlier filtering\n",
    "\n",
    "for c in df_for_outlier_calc.columns:\n",
    "    mean_val = delay_df.agg({c: 'mean'}).collect()[0][0]\n",
    "    stddev_val = delay_df.agg({c: 'stddev'}).collect()[0][0]\n",
    "\n",
    "    # Create three standard deviation (μ ± 3.3σ) lower and upper bounds for data\n",
    "    # Use 3.3 since our data is not normally distrubuted and we should expand bounds to deal with this \n",
    "    low_bound = mean_val - (3.3 * stddev_val)\n",
    "    hi_bound = mean_val + (3.3 * stddev_val)\n",
    "\n",
    "    # Filter the data to fit between the lower and upper bounds\n",
    "    delay_df = delay_df.where((delay_df[c] < hi_bound) & (delay_df[c] > low_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5053782"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I get rid of these outliers or impute them? It seems like a lot of data to impute or get rid of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09085106069094234"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.filter(outliers.DEPARTURE_DELAY_outlier == 'true').count() \\\n",
    "/(delay_df.select('DEPARTURE_DELAY').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05326207715443332"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.filter(outliers.ARRIVAL_DELAY_outlier == 'true').count()\\\n",
    "/(delay_df.select('ARRIVAL_DELAY').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006151443841690539"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.where((outliers.DISTANCE_outlier == 'true') & (outliers.ELAPSED_TIME_outlier == 'true')).count()/(outliers.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06640188953955713"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.filter(outliers.ELAPSED_TIME_outlier == 'true').count()\\\n",
    "/(delay_df.select('ELAPSED_TIME').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider creating a variable that uses a ratio of elasped time to distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that contain outliers: \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder \n",
    "\n",
    "We want to use OneHotEncoder on the string type variables: \n",
    "'AIRLINE', 'DESTINATION_AIRPORT' ,' ORGIN_AIRPORT' \n",
    "to represent them in a numerical form.\n",
    "\n",
    "Maps a column of label indices to a column of binary vectors, with at most a single one-value. This is the same as dummy coding. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features.\n",
    "\n",
    "\n",
    "An intermediate step is to use StringIndexer.\n",
    "StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "spark= SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OneHotEncoder to AIRLINE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"AIRLINE\", outputCol=\"AIRLINE_Index\")\n",
    "model = stringIndexer.fit(delay_df)\n",
    "indexed = model.transform(delay_df)\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"AIRLINE_Index\", outputCol=\"AIRLINE_Vec\")\n",
    "encoded = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply OneHotEncoder to Orgin_AIRPORT: \n",
    "\n",
    "Is there a way ro encode origin_airport and destination_airport \n",
    "together so the same airports have the same encoder inboth columns? \n",
    "\n",
    "How do we use OneHotEncoder column?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer2 = StringIndexer(inputCol=\"ORIGIN_AIRPORT\", outputCol=\"ORIGIN_AIRPORT_Index\")\n",
    "model2 = stringIndexer2.fit(encoded)\n",
    "indexed2 = model2.transform(encoded)\n",
    "\n",
    "encoder2 = OneHotEncoder(inputCol=\"ORIGIN_AIRPORT_Index\", outputCol=\"ORIGIN_AIRPORT_Vec\")\n",
    "encoded2 = encoder2.transform(indexed2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+-----------------------+\n",
      "|DESTINATION_AIRPORT|DESTINATION_AIRPORT_Index|DESTINATION_AIRPORT_Vec|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "|                SEA|                     10.0|       (626,[10],[1.0])|\n",
      "|                PBI|                     53.0|       (626,[53],[1.0])|\n",
      "|                CLT|                     14.0|       (626,[14],[1.0])|\n",
      "|                MIA|                     24.0|       (626,[24],[1.0])|\n",
      "|                ANC|                     68.0|       (626,[68],[1.0])|\n",
      "|                MSP|                      9.0|        (626,[9],[1.0])|\n",
      "|                MSP|                      9.0|        (626,[9],[1.0])|\n",
      "|                CLT|                     14.0|       (626,[14],[1.0])|\n",
      "|                DFW|                      2.0|        (626,[2],[1.0])|\n",
      "|                ATL|                      0.0|        (626,[0],[1.0])|\n",
      "|                ATL|                      0.0|        (626,[0],[1.0])|\n",
      "|                MIA|                     24.0|       (626,[24],[1.0])|\n",
      "|                MSP|                      9.0|        (626,[9],[1.0])|\n",
      "|                ATL|                      0.0|        (626,[0],[1.0])|\n",
      "|                MSP|                      9.0|        (626,[9],[1.0])|\n",
      "|                SEA|                     10.0|       (626,[10],[1.0])|\n",
      "|                SEA|                     10.0|       (626,[10],[1.0])|\n",
      "|                IAH|                      5.0|        (626,[5],[1.0])|\n",
      "|                PDX|                     31.0|       (626,[31],[1.0])|\n",
      "|                MSP|                      9.0|        (626,[9],[1.0])|\n",
      "+-------------------+-------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[YEAR: int, MONTH: int, DAY: int, DAY_OF_WEEK: int, AIRLINE: string, FLIGHT_NUMBER: int, ORIGIN_AIRPORT: string, DESTINATION_AIRPORT: string, SCHEDULED_DEPARTURE: int, DEPARTURE_TIME: int, DEPARTURE_DELAY: int, SCHEDULED_TIME: int, ELAPSED_TIME: int, DISTANCE: int, SCHEDULED_ARRIVAL: int, ARRIVAL_TIME: int, ARRIVAL_DELAY: int, DIVERTED: int, CANCELLED: int, AIRLINE_Index: double, AIRLINE_Vec: vector, ORIGIN_AIRPORT_Index: double, ORIGIN_AIRPORT_Vec: vector, DESTINATION_AIRPORT_Index: double, DESTINATION_AIRPORT_Vec: vector]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each level, count freq. val=0 for most freq, then 1, ...\n",
    "\n",
    "stringIndexer3 = StringIndexer(inputCol=\"DESTINATION_AIRPORT\", outputCol=\"DESTINATION_AIRPORT_Index\")\n",
    "model3 = stringIndexer3.fit(encoded2)\n",
    "indexed3 = model3.transform(encoded2)\n",
    "\n",
    "encoder3 = OneHotEncoder(inputCol=\"DESTINATION_AIRPORT_Index\", outputCol=\"DESTINATION_AIRPORT_Vec\")\n",
    "encoded3 = encoder3.transform(indexed3)\n",
    "encoded3.select('DESTINATION_AIRPORT','DESTINATION_AIRPORT_Index', \"DESTINATION_AIRPORT_Vec\").show()\n",
    "encoded3.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecesary Columns from encoded3 dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_to_drop = ['AIRLINE_Index', 'AIRLINE', 'ORIGIN_AIRPORT_Index', \n",
    "                                   'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT_Index', 'DESTINATION_AIRPORT']\n",
    "\n",
    "final_encoded = encoded3.drop(*new_cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have a completly numerical data set! We should bucketize for time and then should be reayd tp start running models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------------+------------+--------+-----------------+------------+-------------+--------+---------+---------------+------------------+-----------------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|FLIGHT_NUMBER|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|SCHEDULED_TIME|ELAPSED_TIME|DISTANCE|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|    AIRLINE_Vec|ORIGIN_AIRPORT_Vec|DESTINATION_AIRPORT_Vec|\n",
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------------+------------+--------+-----------------+------------+-------------+--------+---------+---------------+------------------+-----------------------+\n",
      "|2015|    1|  1|          4|           98|                  5|          2354|            -11|           205|         194|    1448|              430|         408|          -22|       0|        0| (13,[9],[1.0])|  (625,[69],[1.0])|       (626,[10],[1.0])|\n",
      "|2015|    1|  1|          4|         2336|                 10|             2|             -8|           280|         279|    2330|              750|         741|           -9|       0|        0| (13,[2],[1.0])|   (625,[3],[1.0])|       (626,[53],[1.0])|\n",
      "|2015|    1|  1|          4|          840|                 20|            18|             -2|           286|         293|    2296|              806|         811|            5|       0|        0| (13,[8],[1.0])|   (625,[5],[1.0])|       (626,[14],[1.0])|\n",
      "|2015|    1|  1|          4|          258|                 20|            15|             -5|           285|         281|    2342|              805|         756|           -9|       0|        0| (13,[2],[1.0])|   (625,[3],[1.0])|       (626,[24],[1.0])|\n",
      "|2015|    1|  1|          4|          135|                 25|            24|             -1|           235|         215|    1448|              320|         259|          -21|       0|        0| (13,[9],[1.0])|  (625,[10],[1.0])|       (626,[68],[1.0])|\n",
      "|2015|    1|  1|          4|          806|                 25|            20|             -5|           217|         230|    1589|              602|         610|            8|       0|        0| (13,[1],[1.0])|   (625,[5],[1.0])|        (626,[9],[1.0])|\n",
      "|2015|    1|  1|          4|          612|                 25|            19|             -6|           181|         170|    1299|              526|         509|          -17|       0|        0|(13,[10],[1.0])|   (625,[8],[1.0])|        (626,[9],[1.0])|\n",
      "|2015|    1|  1|          4|         2013|                 30|            44|             14|           273|         249|    2125|              803|         753|          -10|       0|        0| (13,[8],[1.0])|   (625,[3],[1.0])|       (626,[14],[1.0])|\n",
      "|2015|    1|  1|          4|         1112|                 30|            19|            -11|           195|         193|    1464|              545|         532|          -13|       0|        0| (13,[2],[1.0])|   (625,[5],[1.0])|        (626,[2],[1.0])|\n",
      "|2015|    1|  1|          4|         1173|                 30|            33|              3|           221|         203|    1747|              711|         656|          -15|       0|        0| (13,[1],[1.0])|   (625,[8],[1.0])|        (626,[0],[1.0])|\n",
      "|2015|    1|  1|          4|         2336|                 30|            24|             -6|           173|         149|    1199|              523|         453|          -30|       0|        0| (13,[1],[1.0])|   (625,[4],[1.0])|        (626,[0],[1.0])|\n",
      "|2015|    1|  1|          4|         1674|                 35|            27|             -8|           268|         266|    2174|              803|         753|          -10|       0|        0| (13,[2],[1.0])|   (625,[8],[1.0])|       (626,[24],[1.0])|\n",
      "|2015|    1|  1|          4|         1434|                 35|            35|              0|           214|         210|    1535|              609|         605|           -4|       0|        0| (13,[1],[1.0])|   (625,[3],[1.0])|        (626,[9],[1.0])|\n",
      "|2015|    1|  1|          4|         2324|                 40|            34|             -6|           215|         199|    1590|              615|         553|          -22|       0|        0| (13,[1],[1.0])|  (625,[16],[1.0])|        (626,[0],[1.0])|\n",
      "|2015|    1|  1|          4|         2440|                 40|            39|             -1|           189|         198|    1399|              549|         557|            8|       0|        0| (13,[1],[1.0])|  (625,[10],[1.0])|        (626,[9],[1.0])|\n",
      "+----+-----+---+-----------+-------------+-------------------+--------------+---------------+--------------+------------+--------+-----------------+------------+-------------+--------+---------+---------------+------------------+-----------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_encoded.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
